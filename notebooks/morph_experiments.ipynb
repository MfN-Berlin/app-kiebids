{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf4d2536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from lxml import etree\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import pytesseract\n",
    "\n",
    "from kiebids.modules.evaluation import load_image_from_url\n",
    "from kiebids import config\n",
    "\n",
    "folder_path =  os.path.join(\n",
    "    config.shared_folder,\n",
    "    \"data/hymdata_sample/20230511T160908__coll.mfn-berlin.de_u_78a081\",\n",
    ")\n",
    "\n",
    "output_path = \"../data/tmp\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aa18487",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_images = 20\n",
    "index = 10\n",
    "files = [f for f in os.listdir(folder_path) if f.endswith(\".xml\")][index:max_images+index]\n",
    "def get_image(index):\n",
    "    if index > len(files):\n",
    "        raise ValueError(\"Index out of range\")\n",
    "\n",
    "    filename = files[index]\n",
    "\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    tree = etree.parse(file_path)\n",
    "    root = tree.getroot()\n",
    "    ns = {\"ns\": root.nsmap[None]} if None in root.nsmap else {}\n",
    "\n",
    "    comments = root.find(\n",
    "        \".//ns:Metadata/ns:Comments\" if ns else \".//Metadata/Comments\",\n",
    "        namespaces=ns,\n",
    "    )\n",
    "    # excluding some fields without assignment\n",
    "    comments = dict(item.split(\"=\", 1) for item in comments.text.split(\", \") if len(item.split(\"=\", 1)) == 2)\n",
    "\n",
    "    # loading from url\n",
    "    image_url = comments.get(\"imgUrl\")\n",
    "    image = None\n",
    "    if image_url:\n",
    "        image = load_image_from_url(image_url)\n",
    "        grayscale_image = image.convert('L')\n",
    "\n",
    "        # Convert the grayscale PIL image to a NumPy array (of type uint8)\n",
    "        grayscale_np = np.array(grayscale_image, dtype=np.uint8)\n",
    "        # image = grayscale_image\n",
    "    return image, grayscale_np\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9545f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, grayscale_np = get_image(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6724a227",
   "metadata": {},
   "source": [
    "#### resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4149fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizing for experinments with kernel size\n",
    "up_points = (grayscale_np.shape[1] * 4, grayscale_np.shape[0] * 4)\n",
    "resized_image = cv2.resize(grayscale_np, up_points, interpolation= cv2.INTER_LINEAR)\n",
    "\n",
    "image = resized_image\n",
    "print(f\"original image shape: {grayscale_np.shape}\")\n",
    "print(f\"resized image shape: {resized_image.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e531a15",
   "metadata": {},
   "source": [
    "## Thresholding and Morph operations\n",
    "https://docs.opencv2.org/3.4/d7/d4d/tutorial_py_thresholding.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75779414",
   "metadata": {},
   "source": [
    "### original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd196fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7d306b",
   "metadata": {},
   "source": [
    "### Adaptive Thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6eaa20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, f in enumerate(files):\n",
    "    image, grayscale_np = get_image(i)\n",
    "\n",
    "    denoised = cv2.fastNlMeansDenoising(grayscale_np,None,10,10,7)\n",
    "\n",
    "    t = 100\n",
    "    alg = cv2.ADAPTIVE_THRESH_MEAN_C\n",
    "    alg = cv2.ADAPTIVE_THRESH_GAUSSIAN_C\n",
    "    t_type = \"adaptive\"\n",
    "    if t_type == \"adaptive\":\n",
    "        print(\"adaptive thresholding\")\n",
    "        thresholded_image = cv2.adaptiveThreshold(denoised, 255, alg, \n",
    "                                                cv2.THRESH_BINARY, 19, 20)\n",
    "    else:\n",
    "        t = 30\n",
    "        print(\"binary thresholding\")\n",
    "        ret, thresholded_image = cv2.threshold(denoised, t,255,cv2.THRESH_BINARY)\n",
    "\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    opening = cv2.morphologyEx(thresholded_image, cv2.MORPH_OPEN, kernel)\n",
    "    # removing outer border\n",
    "    offset = 20\n",
    "    opening = opening[offset:opening.shape[0]-offset, offset:opening.shape[1]-offset]\n",
    "\n",
    "    # kernel = np.ones((3,3),np.uint8)\n",
    "    closing = cv2.morphologyEx(thresholded_image, cv2.MORPH_CLOSE, kernel)\n",
    "\n",
    "    kernel = np.ones((3,3),np.uint8)\n",
    "    eroded = cv2.erode(opening, kernel, iterations=1)\n",
    "\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(10, 10))\n",
    "\n",
    "    # Plot each image in the respective subplot\n",
    "    axes[0, 0].imshow(grayscale_np, cmap='gray')\n",
    "    axes[0, 0].set_title(\"greyscale image\")\n",
    "    axes[0, 0].axis('off')  # Remove axes for better visualization\n",
    "\n",
    "    axes[1, 0].imshow(thresholded_image, cmap='gray')\n",
    "    axes[1, 0].set_title(\"thresholded image\")\n",
    "    axes[1, 0].axis('off')\n",
    "\n",
    "    axes[0, 1].imshow(denoised, cmap='gray')\n",
    "    axes[0, 1].set_title(\"denoised\")\n",
    "    axes[0, 1].axis('off')\n",
    "\n",
    "    axes[1, 1].imshow(opening, cmap='gray')\n",
    "    axes[1, 1].set_title(\"opening\")\n",
    "    axes[1, 1].axis('off')\n",
    "\n",
    "    axes[2, 0].imshow(closing, cmap='gray')\n",
    "    axes[2, 0].set_title(\"closing\")\n",
    "    axes[2, 0].axis('off')\n",
    "\n",
    "    axes[2, 1].imshow(eroded, cmap='gray')\n",
    "    axes[2, 1].set_title(\"eroded opening\")\n",
    "    axes[2, 1].axis('off')\n",
    "\n",
    "    # Adjust layout to avoid overlapping\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig(f\"{output_path}/{f.replace('.xml', '_combined.jpg')}\", dpi=300, bbox_inches='tight')            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b822c141",
   "metadata": {},
   "outputs": [],
   "source": [
    "opening = cv2.imread(\"../data/tmp/88dd7970-fbac-4321-a15b-1ad6adfbb269_label_front_0001_label_opening.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "rgb_image = cv2.cvtColor(opening, cv2.COLOR_GRAY2BGR)\n",
    "boxes = pytesseract.image_to_boxes(opening)\n",
    "\n",
    "# contours, _ = cv2.findContours(opening, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "contours, _ = cv2.findContours(opening, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "print(len(contours))\n",
    "\n",
    "# cv2.drawContours(rgb_image, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "# cv2.imwrite(f\"{output_path}/{f.replace('.xml', '_contours.jpg')}\", rgb_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4805c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "opening = cv2.imread(\"../data/tmp/88dd7970-fbac-4321-a15b-1ad6adfbb269_label_front_0001_label_opening.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "rgb_image = cv2.cvtColor(opening, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "layerNames = [\n",
    "\t\"feature_fusion/Conv_7/Sigmoid\",\n",
    "\t\"feature_fusion/concat_3\"]\n",
    "net = cv2.dnn.readNet()\n",
    "\n",
    "blob = cv2.dnn.blobFromImage(image, 1.0, (W, H),\n",
    "\t(123.68, 116.78, 103.94), swapRB=True, crop=False)\n",
    "net.setInput(blob)\n",
    "(scores, geometry) = net.forward(layerNames)\n",
    "\n",
    "# (rects, confidences) = decode_predictions(scores, geometry)\n",
    "# boxes = non_max_suppression(np.array(rects), probs=confidences)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605e2e49",
   "metadata": {},
   "source": [
    "### Opening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b4627",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3),np.uint8)\n",
    "opening = cv2.morphologyEx(thresholded_image, cv2.MORPH_OPEN, kernel)\n",
    "plt.imshow(opening, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4f0063",
   "metadata": {},
   "source": [
    "### Closing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851bf28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((3,3),np.uint8)\n",
    "closing = cv2.morphologyEx(thresholded_image, cv2.MORPH_CLOSE, kernel)\n",
    "plt.imshow(closing, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e0dce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
