{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import sys\n",
    "from lxml import etree\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from kiebids.utils import crop_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_path = \"../data/evaluation/tensorboard\"\n",
    "id = \"20241220-112659\"\n",
    "experiment_path = f\"{evaluation_path}/{id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tb_data(root_dir, sort_by=None):\n",
    "    \"\"\"Convert local TensorBoard data into Pandas DataFrame.\n",
    "\n",
    "    Function takes the root directory path and recursively parses\n",
    "    all events data.\n",
    "    If the `sort_by` value is provided then it will use that column\n",
    "    to sort values; typically `wall_time` or `step`.\n",
    "\n",
    "    *Note* that the whole data is converted into a DataFrame.\n",
    "    Depending on the data size this might take a while. If it takes\n",
    "    too long then narrow it to some sub-directories.\n",
    "\n",
    "    Paramters:\n",
    "        root_dir: (str) path to root dir with tensorboard data.\n",
    "        sort_by: (optional str) column name to sort by.\n",
    "\n",
    "    Returns:\n",
    "        pandas.DataFrame with [wall_time, name, step, value] columns.\n",
    "\n",
    "    \"\"\"\n",
    "    import os\n",
    "    from tensorflow.python.summary.summary_iterator import summary_iterator\n",
    "\n",
    "    def convert_tfevent(filepath):\n",
    "        return pd.DataFrame(\n",
    "            [\n",
    "                parse_tfevent(e)\n",
    "                for e in summary_iterator(filepath)\n",
    "                if len(e.summary.value)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def parse_tfevent(tfevent):\n",
    "        return dict(\n",
    "            wall_time=tfevent.wall_time,\n",
    "            name=tfevent.summary.value[0].tag,\n",
    "            step=tfevent.step,\n",
    "            value=float(tfevent.summary.value[0].simple_value),\n",
    "        )\n",
    "\n",
    "    columns_order = [\"wall_time\", \"name\", \"step\", \"value\"]\n",
    "\n",
    "    out = []\n",
    "    for root, _, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "            if \"events.out.tfevents\" not in filename:\n",
    "                continue\n",
    "            file_full_path = os.path.join(root, filename)\n",
    "            out.append(convert_tfevent(file_full_path))\n",
    "\n",
    "    # Concatenate (and sort) all partial individual dataframes\n",
    "\n",
    "    all_df = pd.concat(out)[columns_order]\n",
    "\n",
    "    pivoted = (\n",
    "        pd.pivot_table(all_df, columns=\"name\", values=[\"value\"], index=[\"step\"])\n",
    "        .droplevel(0, axis=1)\n",
    "        .reset_index()\n",
    "        .drop(columns=[\"step\"])\n",
    "        .rename_axis(None)\n",
    "    )\n",
    "    pivoted.columns.name = None\n",
    "    return pivoted\n",
    "\n",
    "\n",
    "def map_image_to_index(path):\n",
    "    files = os.listdir(path)\n",
    "    mapping = {}\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            with open(os.path.join(path, file), \"r\") as f:\n",
    "                data = json.load(f)\n",
    "\n",
    "            if isinstance(data, dict) and \"image_index\" in data.keys():\n",
    "                mapping[data[\"image_index\"]] = file.split(\".\")[0]\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    return mapping\n",
    "\n",
    "\n",
    "def read_xml(file_path: str) -> dict:\n",
    "    \"\"\"\n",
    "    Parses an XML file and extracts information about pages, text regions, and text lines.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the XML file to be parsed.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the extracted information with the following structure:\n",
    "            {\n",
    "                \"image_filename\": str,  # The filename of the image associated with the page\n",
    "                \"image_width\": str,     # The width of the image\n",
    "                \"image_height\": str,    # The height of the image\n",
    "                \"text_regions\": [       # A list of text regions\n",
    "                    {\n",
    "                        \"id\": str,           # The ID of the text region\n",
    "                        \"orientation\": str,  # The orientation of the text region\n",
    "                        \"coords\": str,       # The coordinates of the text region\n",
    "                        \"text\": str,         # The text content of the whole text region\n",
    "                        \"text_lines\": [      # A list of text lines within the text region\n",
    "                            {\n",
    "                                \"id\": str,        # The ID of the text line\n",
    "                                \"coords\": str,    # The coordinates of the text line\n",
    "                                \"baseline\": str,  # The baseline coordinates of the text line\n",
    "                                \"text\": str       # The text content of the text line\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "    \"\"\"\n",
    "\n",
    "    tree = etree.parse(file_path)  # noqa: S320  # Using `lxml` to parse untrusted data is known to be vulnerable to XML attacks\n",
    "    ns = {\"ns\": tree.getroot().nsmap.get(None, \"\")}\n",
    "\n",
    "    page = tree.find(\".//ns:Page\", namespaces=ns)\n",
    "    output = {\n",
    "        \"image_filename\": page.get(\"imageFilename\"),\n",
    "        \"image_width\": page.get(\"imageWidth\"),\n",
    "        \"image_height\": page.get(\"imageHeight\"),\n",
    "        \"text_regions\": [],\n",
    "    }\n",
    "\n",
    "    for region in page.findall(\".//ns:TextRegion\", namespaces=ns):\n",
    "        text_region = {\n",
    "            \"id\": region.get(\"id\"),\n",
    "            \"orientation\": region.get(\"orientation\"),\n",
    "            \"coords\": region.find(\".//ns:Coords\", namespaces=ns).get(\"points\"),\n",
    "            \"text\": (\n",
    "                region.findall(\".//ns:TextEquiv\", namespaces=ns)[-1]\n",
    "                .find(\".//ns:Unicode\", namespaces=ns)\n",
    "                .text\n",
    "                or \"\"\n",
    "            ),\n",
    "            \"text_lines\": [],\n",
    "        }\n",
    "\n",
    "        output[\"text_regions\"].append(text_region)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_tb_data(experiment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Data with num ground_truth != num text predictions: {len(df.dropna(subset='Text_recognition/_average_CER'))} / {len(df)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.hist(column=\"Layout_analysis/_average_ious\", bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.plot.hist(column=\"Text_recognition/_average_CER\", bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the relatively \"good\" results\n",
    "df.plot.hist(column=\"Text_recognition/_average_CER\", bins=100, range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_results = df[df[\"Text_recognition/_average_CER\"] < 0.6]\n",
    "bad_results = df[df[\"Text_recognition/_average_CER\"] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_mapping = map_image_to_index(\"../data/debug/text_recognition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "good_images = [image_mapping[index] for index in good_results.index]\n",
    "bad_images = [image_mapping[index] for index in bad_results.index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"Good\" results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the good results\n",
    "i = 8\n",
    "\n",
    "# Image\n",
    "image_path = \"../data/debug/preprocessing\"\n",
    "image = Image.open(os.path.join(image_path, good_images[i] + \".JPG\"))\n",
    "array_image = cv2.imread(os.path.join(image_path, good_images[i] + \".JPG\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get text_recognition results\n",
    "results_path = \"../data/output\"\n",
    "xml = read_xml(os.path.join(results_path, good_images[i] + \".xml\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print\n",
    "regions = xml[\"text_regions\"]\n",
    "for region in regions:\n",
    "    # Imgage\n",
    "    coords = [int(coord) for coord in region[\"coords\"].split(\" \")]\n",
    "    cropped_image = crop_image(array_image, coords)\n",
    "    display(Image.fromarray(cropped_image))\n",
    "    print(region[\"text\"])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poor results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the good results\n",
    "i = 7\n",
    "\n",
    "# Image\n",
    "image_path = \"../data/debug/preprocessing\"\n",
    "image = Image.open(os.path.join(image_path, bad_images[i] + \".JPG\"))\n",
    "print(bad_images[i])\n",
    "array_image = cv2.imread(os.path.join(image_path, bad_images[i] + \".JPG\"))\n",
    "xml = read_xml(os.path.join(results_path, bad_images[i] + \".xml\"))\n",
    "regions = xml[\"text_regions\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in regions:\n",
    "    # Imgage\n",
    "    coords = [int(coord) for coord in region[\"coords\"].split(\" \")]\n",
    "    cropped_image = crop_image(array_image, coords)\n",
    "    display(Image.fromarray(cropped_image))\n",
    "    print(region[\"text\"])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
